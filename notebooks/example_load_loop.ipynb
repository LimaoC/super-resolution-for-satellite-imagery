{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from super_resolution.src.sen2venus_dataset import (\n",
    "    create_train_validation_test_split,\n",
    "    default_patch_transform,\n",
    ")\n",
    "from super_resolution.src.visualization import plot_gallery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = pathlib.Path(\"C:/Users/Mitch/stat3007_data\")\n",
    "SITES_DIR = DATA_DIR / \"sites\"\n",
    "PREPROCESSING_DIR = DATA_DIR / \"preprocessing\"\n",
    "RESULTS_DIR = DATA_DIR / \"results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_patches, val_patches, test_patches = create_train_validation_test_split(\n",
    "    str(SITES_DIR) + \"\\\\\", sites={\"K34-AMAZ\"}\n",
    ")\n",
    "print(\n",
    "    f\"Num train {len(train_patches)}\\n\"\n",
    "    f\"Num validation {len(val_patches)}\\n\"\n",
    "    f\"Num test {len(test_patches)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_patches, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (low_res, high_res) in enumerate(train_loader):\n",
    "    print(\n",
    "        f\"batch {i}\\n\"\n",
    "        f\"low resolution batch shape {low_res.shape}\\n\"\n",
    "        f\"high resolution batch shape {high_res.shape}\\n\"\n",
    "    )\n",
    "\n",
    "    if i == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "index = random.randint(0, len(low_res) - 1)\n",
    "\n",
    "low_res_example = low_res[index]\n",
    "high_res_example = high_res[index]\n",
    "\n",
    "plot_gallery(\n",
    "\n",
    "    [low_res_example.permute(1, 2, 0), high_res_example.permute(1, 2, 0)],\n",
    "\n",
    "    xscale=5,\n",
    "\n",
    "    yscale=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading with transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We often want to apply some transforms calculated from our training set and apply these\n",
    "to both the training set and test sets before running data through our model. These custom transforms\n",
    "are useful for training stability and normalization. This gives us another component of the model we\n",
    "can experiment with if we choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~2min\n",
    "# Compute mean and standard deviation for each channel (averaged over samples).\n",
    "train_loader = DataLoader(train_patches, batch_size=1000)\n",
    "\n",
    "mean = 0.0\n",
    "std = 0.0\n",
    "for i, (low_res, _) in enumerate(train_loader):\n",
    "    mean += torch.sum(torch.mean(low_res, (2, 3)), 0)\n",
    "    std += torch.sum(torch.std(low_res, (2, 3)), 0)\n",
    "mean /= len(train_patches)\n",
    "std /= len(train_patches)\n",
    "print(f\"Channel means {mean}\\n\" f\"Channel standard deviations {std}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the mean and std can be slow. Here is some code for saving and loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = PREPROCESSING_DIR / \"K34-AMAZ_mean_std.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(save_file, \"wb\") as file:\n",
    "#     pickle.dump((mean, std), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(save_file, \"rb\") as file:\n",
    "#     mean, std = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_transform(\n",
    "    low_res_patch: torch.Tensor, high_res_patch: torch.Tensor\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    augmentations = transforms.Compose(\n",
    "        [\n",
    "            transforms.Normalize(mean, std),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Basic transforms such as removing 4th channel and scaling surface reflectants\n",
    "    low_res_patch, high_res_patch = default_patch_transform(\n",
    "        low_res_patch, high_res_patch\n",
    "    )\n",
    "\n",
    "    # torchvision transforms expects shape (CxHxW) so permute accordingly\n",
    "    low_res_patch = low_res_patch.permute(0, 2, 1)\n",
    "    low_res_augmented = augmentations(low_res_patch).permute(0, 2, 1)\n",
    "\n",
    "    return low_res_augmented, high_res_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_patches.set_transform(custom_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images will now be loaded with the above custom transform applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(3, 3, 3, 1, 65)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleSR()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Loop Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "should_pin_memory = {\"cuda\": True, \"cpu\": False}\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_patches,\n",
    "    shuffle=True,  # Always set to true for training\n",
    "    batch_size=128,  # Always try to set as powers of 2\n",
    "    drop_last=True,  # Ensures batch size is always the one given (Drops last if its is smaller)\n",
    "    pin_memory=should_pin_memory[device.type],  # Faster push to GPU\n",
    "    num_workers=2,  # Load data in parallel but costs more memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~21min for 10 epochs\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "losses = []\n",
    "epoch_losses = []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    progress_bar = tqdm.tqdm(train_loader, total=len(train_loader), ncols=100)\n",
    "    epoch_loss = 0.0\n",
    "    for low_res_batch, high_res_batch in progress_bar:\n",
    "        # Push to GPU\n",
    "        low_res_batch = low_res_batch.to(device)\n",
    "        high_res_batch = high_res_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Loss and update\n",
    "        out = model(low_res_batch)\n",
    "        loss = criterion(out, high_res_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Collect data\n",
    "        epoch_loss += loss.item()\n",
    "        losses.append(loss.item())\n",
    "        progress_bar.set_postfix(epoch=epoch, batch_loss=loss.item())\n",
    "\n",
    "    epoch_loss /= len(train_loader)\n",
    "    epoch_losses.append(epoch_loss)\n",
    "    print(f\"Epoch: {epoch} / loss: {epoch_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = {\n",
    "    \"epoch_losses\": epoch_losses,\n",
    "    \"batch_losses\": losses,\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"optimizer_state\": optimizer.state_dict(),\n",
    "}\n",
    "save_file = RESULTS_DIR / \"basic_sr_results.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(save_file, \"wb\") as file:\n",
    "#     pickle.dump(experiment, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(save_file, \"rb\") as file:\n",
    "#     experiment = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.title(\"Losses for each minibatch\")\n",
    "plt.xlabel(\"Minibatch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_losses)\n",
    "plt.title(\"Losses for each epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Mean MSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(low_res_example.unsqueeze(0)).squeeze(0)\n",
    "out = (out - out.min()) / (out.max() - out.min())\n",
    "plot_gallery(\n",
    "    [\n",
    "        low_res_example.permute(1, 2, 0),\n",
    "        high_res_example.permute(1, 2, 0),\n",
    "        out.permute(1, 2, 0),\n",
    "    ],\n",
    "    xscale=5,\n",
    "    yscale=5,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "getafix_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
