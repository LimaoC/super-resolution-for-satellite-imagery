{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pathlib\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.modules.loss import _Loss\n",
    "\n",
    "from super_resolution.src.sen2venus_dataset import create_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = pathlib.Path(\"C:/Users/Mitch/stat3007_data\")\n",
    "SITES_DIR = DATA_DIR / \"sites\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Helpers -----\n",
    "\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "\n",
    "class UnFlatten(nn.Module):\n",
    "    def __init__(self, unflatten_size):\n",
    "        super().__init__()\n",
    "        if isinstance(unflatten_size, tuple):\n",
    "            self.c = unflatten_size[0]\n",
    "            self.h = unflatten_size[1]\n",
    "            self.w = unflatten_size[2]\n",
    "        elif isinstance(unflatten_size, int):\n",
    "            self.c = unflatten_size\n",
    "            self.h = 1\n",
    "            self.w = 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), self.c, self.h, self.w)\n",
    "\n",
    "\n",
    "# ----- 2D Convolutions -----\n",
    "\n",
    "\n",
    "# Conv2d init_parameters from: https://github.com/vlievin/biva-pytorch/blob/master/biva/layers/convolution.py\n",
    "class Conv2d(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size=3,\n",
    "        stride=1,\n",
    "        padding=0,\n",
    "        dilation=1,\n",
    "        groups=1,\n",
    "        bias=True,\n",
    "        weightnorm=True,\n",
    "        act=None,\n",
    "        drop_prob=0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.weightnorm = weightnorm\n",
    "        self.initialized = True\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=bias,\n",
    "        )\n",
    "\n",
    "        self.act = nn.ELU(inplace=True) if act is not None else Identity()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        if self.weightnorm:\n",
    "            self.initialized = False\n",
    "            self.conv = nn.utils.weight_norm(self.conv, dim=0, name=\"weight\")\n",
    "\n",
    "    def forward(self, input):\n",
    "        if not self.initialized:\n",
    "            self.init_parameters(input)\n",
    "        return F.dropout(self.act(self.conv(input)), p=self.drop_prob, training=True)\n",
    "\n",
    "    def init_parameters(self, x, init_scale=0.05, eps=1e-8):\n",
    "        self.initialized = True\n",
    "        if self.weightnorm:\n",
    "            # initial values\n",
    "            self.conv._parameters[\"weight_v\"].data.normal_(mean=0, std=init_scale)\n",
    "            self.conv._parameters[\"weight_g\"].data.fill_(1.0)\n",
    "            self.conv._parameters[\"bias\"].data.fill_(0.0)\n",
    "            init_scale = 0.01\n",
    "            # data dependent init\n",
    "            x = self.conv(x)\n",
    "            t = x.view(x.size()[0], x.size()[1], -1)\n",
    "            t = t.permute(0, 2, 1).contiguous()\n",
    "            t = t.view(-1, t.size()[-1])\n",
    "            m_init, v_init = torch.mean(t, 0), torch.var(t, 0)\n",
    "            scale_init = init_scale / torch.sqrt(v_init + eps)\n",
    "\n",
    "            self.conv._parameters[\"weight_g\"].data = self.conv._parameters[\n",
    "                \"weight_g\"\n",
    "            ].data * scale_init[:, None].view(\n",
    "                self.conv._parameters[\"weight_g\"].data.size()\n",
    "            )\n",
    "            self.conv._parameters[\"bias\"].data = (\n",
    "                self.conv._parameters[\"bias\"].data - m_init * scale_init\n",
    "            )\n",
    "            return scale_init[None, :, None, None] * (x - m_init[None, :, None, None])\n",
    "\n",
    "\n",
    "class ConvTranspose2d(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size=3,\n",
    "        stride=1,\n",
    "        padding=1,\n",
    "        output_padding=0,\n",
    "        dilation=1,\n",
    "        groups=1,\n",
    "        bias=True,\n",
    "        weightnorm=True,\n",
    "        act=None,\n",
    "        drop_prob=0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.weightnorm = weightnorm\n",
    "        self.initialized = True\n",
    "\n",
    "        self.conv = nn.ConvTranspose2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            output_padding=output_padding,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=bias,\n",
    "        )\n",
    "\n",
    "        self.act = nn.ELU(inplace=True) if act is not None else Identity()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        if self.weightnorm:\n",
    "            self.initialized = False\n",
    "            self.conv = nn.utils.weight_norm(self.conv, dim=1, name=\"weight\")\n",
    "\n",
    "    def forward(self, input):\n",
    "        if not self.initialized:\n",
    "            self.init_parameters(input)\n",
    "        return F.dropout(self.act(self.conv(input)), p=self.drop_prob, training=True)\n",
    "\n",
    "    def init_parameters(self, x, init_scale=0.05, eps=1e-8):\n",
    "        self.initialized = True\n",
    "        if self.weightnorm:\n",
    "            # initial values\n",
    "            self.conv._parameters[\"weight_v\"].data.normal_(mean=0, std=init_scale)\n",
    "            self.conv._parameters[\"weight_g\"].data.fill_(1.0)\n",
    "            self.conv._parameters[\"bias\"].data.fill_(0.0)\n",
    "            init_scale = 0.01\n",
    "            # data dependent init\n",
    "            x = self.conv(x)\n",
    "            t = x.view(x.size()[0], x.size()[1], -1)\n",
    "            t = t.permute(0, 2, 1).contiguous()\n",
    "            t = t.view(-1, t.size()[-1])\n",
    "            m_init, v_init = torch.mean(t, 0), torch.var(t, 0)\n",
    "            scale_init = init_scale / torch.sqrt(v_init + eps)\n",
    "\n",
    "            self.conv._parameters[\"weight_g\"].data = self.conv._parameters[\n",
    "                \"weight_g\"\n",
    "            ].data * scale_init[None, :].view(\n",
    "                self.conv._parameters[\"weight_g\"].data.size()\n",
    "            )\n",
    "            self.conv._parameters[\"bias\"].data = (\n",
    "                self.conv._parameters[\"bias\"].data - m_init * scale_init\n",
    "            )\n",
    "            return scale_init[None, :, None, None] * (x - m_init[None, :, None, None])\n",
    "\n",
    "\n",
    "# ----- Up and Down Sampling -----\n",
    "\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, drop_prob=0.0):\n",
    "        super().__init__()\n",
    "        self.core_nn = nn.Sequential(\n",
    "            Conv2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                drop_prob=drop_prob,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.core_nn(input)\n",
    "\n",
    "\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, drop_prob=0.0):\n",
    "        super().__init__()\n",
    "        self.core_nn = nn.Sequential(\n",
    "            ConvTranspose2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                output_padding=1,\n",
    "                drop_prob=drop_prob,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.core_nn(input)\n",
    "\n",
    "\n",
    "# ----- Gated/Attention Blocks -----\n",
    "\n",
    "\n",
    "class CALayer(nn.Module):\n",
    "    \"\"\"\n",
    "    ChannelWise Gated Layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channel, reduction=8, drop_prob=0.0):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.ca_block = nn.Sequential(\n",
    "            Conv2d(\n",
    "                channel,\n",
    "                channel // reduction,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                drop_prob=drop_prob,\n",
    "            ),\n",
    "            Conv2d(\n",
    "                channel // reduction,\n",
    "                channel,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                act=None,\n",
    "                drop_prob=drop_prob,\n",
    "            ),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.avg_pool(x)\n",
    "        y = self.ca_block(y)\n",
    "        return x * y\n",
    "\n",
    "\n",
    "# ----- DenseNets -----\n",
    "\n",
    "\n",
    "class DenseNetBlock(nn.Module):\n",
    "    def __init__(self, inplanes, growth_rate, drop_prob=0.0):\n",
    "        super().__init__()\n",
    "        self.dense_block = nn.Sequential(\n",
    "            Conv2d(\n",
    "                inplanes,\n",
    "                4 * growth_rate,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                drop_prob=drop_prob,\n",
    "            ),\n",
    "            Conv2d(\n",
    "                4 * growth_rate,\n",
    "                growth_rate,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "                drop_prob=drop_prob,\n",
    "                act=None,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        y = self.dense_block(input)\n",
    "        y = torch.cat([input, y], dim=1)\n",
    "        return y\n",
    "\n",
    "\n",
    "class DenseNetLayer(nn.Module):\n",
    "    def __init__(self, inplanes, growth_rate, steps, drop_prob=0.0):\n",
    "        super().__init__()\n",
    "        self.activation = nn.ELU(inplace=True)\n",
    "\n",
    "        net = []\n",
    "        for step in range(steps):\n",
    "            net.append(DenseNetBlock(inplanes, growth_rate, drop_prob=drop_prob))\n",
    "            net.append(self.activation)\n",
    "            inplanes += growth_rate\n",
    "\n",
    "        net.append(CALayer(inplanes, drop_prob=drop_prob))\n",
    "        self.core_nn = nn.Sequential(*net)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.core_nn(input)\n",
    "\n",
    "\n",
    "class DenselyNetwork(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        growth_rate,\n",
    "        steps,\n",
    "        blocks,\n",
    "        act=None,\n",
    "        drop_prob=0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # downscale block\n",
    "        net = []\n",
    "        for i in range(blocks):\n",
    "            net.append(\n",
    "                DenseNetLayer(in_channels, growth_rate, steps, drop_prob=drop_prob)\n",
    "            )\n",
    "            in_channels = in_channels + growth_rate * steps\n",
    "\n",
    "        # output layer\n",
    "        net.append(\n",
    "            Conv2d(\n",
    "                in_channels, out_channels, kernel_size=1, stride=1, padding=0, act=None\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.core_nn = nn.Sequential(*net)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.core_nn(input)\n",
    "\n",
    "\n",
    "class DenselyEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, growth_rate, steps, scale_factor, drop_prob=0.0\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # downscale block\n",
    "        net = []\n",
    "        for i in range(scale_factor):\n",
    "            net.append(\n",
    "                DenseNetLayer(in_channels, growth_rate, steps, drop_prob=drop_prob)\n",
    "            )\n",
    "            in_channels = in_channels + growth_rate * steps\n",
    "            net.append(Downsample(in_channels, 2 * in_channels, drop_prob=drop_prob))\n",
    "            in_channels *= 2\n",
    "            growth_rate *= 2\n",
    "\n",
    "        # output block\n",
    "        net.append(DenseNetLayer(in_channels, growth_rate, steps, drop_prob=drop_prob))\n",
    "        in_channels = in_channels + growth_rate * steps\n",
    "\n",
    "        # output layer\n",
    "        net.append(\n",
    "            Conv2d(\n",
    "                in_channels, out_channels, kernel_size=1, stride=1, padding=0, act=None\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.core_nn = nn.Sequential(*net)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.core_nn(input)\n",
    "\n",
    "\n",
    "class DenselyDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        growth_rate=16,\n",
    "        steps=3,\n",
    "        scale_factor=2,\n",
    "        drop_prob=0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # upsample block\n",
    "        net = []\n",
    "        for i in range(scale_factor):\n",
    "            net.append(\n",
    "                DenseNetLayer(in_channels, growth_rate, steps, drop_prob=drop_prob)\n",
    "            )\n",
    "            in_channels = in_channels + growth_rate * steps\n",
    "            net.append(Upsample(in_channels, in_channels // 2, drop_prob=drop_prob))\n",
    "            in_channels = in_channels // 2\n",
    "            growth_rate = growth_rate // 2\n",
    "\n",
    "        # output block\n",
    "        net.append(\n",
    "            Conv2d(\n",
    "                in_channels, out_channels, kernel_size=3, stride=1, padding=1, act=None\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.core_nn = nn.Sequential(*net)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.core_nn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributions\n",
    "NMIX = 10\n",
    "\n",
    "\n",
    "def n_embenddings(nc, distribution=\"dmol\"):\n",
    "\n",
    "    if distribution == \"dmol\":\n",
    "        nmix = NMIX\n",
    "        n_emb = (nc * 3 + 1) * nmix\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return n_emb\n",
    "\n",
    "\n",
    "def log_normal_diag(z, z_mu, z_logvar):\n",
    "    eps = 1e-12\n",
    "    log_probs = (\n",
    "        z_logvar + (z - z_mu).pow(2).div(z_logvar.exp() + eps) + math.log(math.pi * 2.0)\n",
    "    )\n",
    "    log_probs = -0.5 * log_probs.view(z.size(0), -1).sum(dim=1)\n",
    "    return log_probs\n",
    "\n",
    "\n",
    "def logsumexp(x, dim=None):\n",
    "    if dim is None:\n",
    "        xmax = x.max()\n",
    "        xmax_ = x.max()\n",
    "        return xmax_ + torch.log(torch.exp(x - xmax).sum())\n",
    "    else:\n",
    "        xmax, _ = x.max(dim, keepdim=True)\n",
    "        xmax_, _ = x.max(dim)\n",
    "        return xmax_ + torch.log(torch.exp(x - xmax).sum(dim))\n",
    "\n",
    "\n",
    "def dmol_loss(x, output, nc=3, nmix=NMIX, nbits=8):\n",
    "    \"\"\"Discretized mix of logistic distributions loss\"\"\"\n",
    "    bits = 2.0**nbits\n",
    "    scale_min, scale_max = [0.0, 1.0]\n",
    "\n",
    "    bin_size = (scale_max - scale_min) / (bits - 1.0)\n",
    "    eps = 1e-12\n",
    "\n",
    "    # unpack values\n",
    "    batch_size, nmix, H, W = output[:, :nmix].size()\n",
    "    logit_probs = output[:, :nmix]\n",
    "    means = output[:, nmix : (nc + 1) * nmix].view(batch_size, nmix, nc, H, W)\n",
    "    logscales = output[:, (nc + 1) * nmix : (nc * 2 + 1) * nmix].view(\n",
    "        batch_size, nmix, nc, H, W\n",
    "    )\n",
    "    coeffs = output[:, (nc * 2 + 1) * nmix : (nc * 2 + 4) * nmix].view(\n",
    "        batch_size, nmix, nc, H, W\n",
    "    )\n",
    "\n",
    "    # activation functions and resize\n",
    "    logit_probs = F.log_softmax(logit_probs, dim=1)\n",
    "    logscales = logscales.clamp(min=-7.0)\n",
    "    coeffs = coeffs.tanh()\n",
    "\n",
    "    x = x.unsqueeze(1)\n",
    "    means = means.view(batch_size, *means.size()[1:])\n",
    "    logscales = logscales.view(batch_size, *logscales.size()[1:])\n",
    "    coeffs = coeffs.view(batch_size, *coeffs.size()[1:])\n",
    "    logit_probs = logit_probs.view(batch_size, *logit_probs.size()[1:])\n",
    "\n",
    "    # channel-wise conditional modelling sub-pixels\n",
    "    mean0 = means[:, :, 0]\n",
    "    mean1 = means[:, :, 1] + coeffs[:, :, 0] * x[:, :, 0]\n",
    "    mean2 = means[:, :, 2] + coeffs[:, :, 1] * x[:, :, 0] + coeffs[:, :, 2] * x[:, :, 1]\n",
    "    means = torch.stack([mean0, mean1, mean2], dim=2)\n",
    "\n",
    "    # compute log CDF for the normal cases (lower < x < upper)\n",
    "    x_plus = torch.exp(-logscales) * (x - means + 0.5 * bin_size)\n",
    "    x_minus = torch.exp(-logscales) * (x - means - 0.5 * bin_size)\n",
    "    cdf_delta = torch.sigmoid(x_plus) - torch.sigmoid(x_minus)\n",
    "    log_cdf_mid = torch.log(cdf_delta.clamp(min=eps))\n",
    "\n",
    "    # Extreme Case #1: x > upper (before scaling)\n",
    "    upper = scale_max - 0.5 * bin_size\n",
    "    mask_upper = x.le(upper).float()\n",
    "    log_cdf_up = -F.softplus(x_minus)\n",
    "\n",
    "    # Extreme Case #2: x < lower (before scaling)\n",
    "    lower = scale_min + 0.5 * bin_size\n",
    "    mask_lower = x.ge(lower).float()\n",
    "    log_cdf_low = x_plus - F.softplus(x_plus)\n",
    "\n",
    "    # Extreme Case #3: probability on a sub-pixel is below 1e-5\n",
    "    #   --> If the probability on a sub-pixel is below 1e-5, we use an approximation\n",
    "    #       based on the assumption that the log-density is constant in the bin of\n",
    "    #       the observed sub-pixel value\n",
    "    x_in = torch.exp(-logscales) * (x - means)\n",
    "    mask_delta = cdf_delta.gt(1e-5).float()\n",
    "    log_cdf_approx = x_in - logscales - 2.0 * F.softplus(x_in) + np.log(bin_size)\n",
    "\n",
    "    # Compute log CDF w/ extrime cases\n",
    "    log_cdf = log_cdf_mid * mask_delta + log_cdf_approx * (1.0 - mask_delta)\n",
    "    log_cdf = log_cdf_low * (1.0 - mask_lower) + log_cdf * mask_lower\n",
    "    log_cdf = log_cdf_up * (1.0 - mask_upper) + log_cdf * mask_upper\n",
    "\n",
    "    # Compute log loss\n",
    "    loss = logsumexp(log_cdf.sum(dim=2) + logit_probs, dim=1)\n",
    "    return loss.view(loss.shape[0], -1).sum(1)\n",
    "\n",
    "\n",
    "def sample_from_dmol(x_mean, nc=3, nmix=NMIX, random_sample=False):\n",
    "    \"\"\"Sample from Discretized mix of logistic distribution\"\"\"\n",
    "    scale_min, scale_max = [0.0, 1.0]\n",
    "\n",
    "    # unpack values\n",
    "    logit_probs = x_mean[:, :nmix]  # pi\n",
    "    batch_size, nmix, H, W = logit_probs.size()\n",
    "    means = x_mean[:, nmix : (nc + 1) * nmix].view(batch_size, nmix, nc, H, W)  # mean\n",
    "    logscales = x_mean[:, (nc + 1) * nmix : (nc * 2 + 1) * nmix].view(\n",
    "        batch_size, nmix, nc, H, W\n",
    "    )  # log_var\n",
    "    coeffs = x_mean[:, (nc * 2 + 1) * nmix : (nc * 2 + 4) * nmix].view(\n",
    "        batch_size, nmix, nc, H, W\n",
    "    )  # chan_coeff\n",
    "\n",
    "    # activation functions\n",
    "    logscales = logscales.clamp(min=-7.0)\n",
    "    logit_probs = F.log_softmax(logit_probs, dim=1)\n",
    "    coeffs = coeffs.tanh()\n",
    "\n",
    "    # sample mixture\n",
    "    index = (\n",
    "        logit_probs.argmax(dim=1, keepdim=True)\n",
    "        + logit_probs.new_zeros(means.size(0), *means.size()[2:]).long()\n",
    "    )\n",
    "    one_hot = means.new_zeros(means.size()).scatter_(1, index.unsqueeze(1), 1)\n",
    "    means = (means * one_hot).sum(dim=1)\n",
    "    logscales = (logscales * one_hot).sum(dim=1)\n",
    "    coeffs = (coeffs * one_hot).sum(dim=1)\n",
    "    x = means\n",
    "\n",
    "    if random_sample:\n",
    "        # sample y from CDF\n",
    "        u = means.new_zeros(means.size()).uniform_(1e-5, 1 - 1e-5)\n",
    "        # from y map it to the corresponing x\n",
    "        x = x + logscales.exp() * (torch.log(u) - torch.log(1.0 - u))\n",
    "\n",
    "    # concat image channels\n",
    "    x0 = (x[:, 0]).clamp(min=scale_min, max=scale_max)\n",
    "    x1 = (x[:, 1] + coeffs[:, 0] * x0).clamp(min=scale_min, max=scale_max)\n",
    "    x2 = (x[:, 2] + coeffs[:, 1] * x0 + coeffs[:, 2] * x1).clamp(\n",
    "        min=scale_min, max=scale_max\n",
    "    )\n",
    "    x = torch.stack([x0, x1, x2], dim=1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class q_u(nn.Module):\n",
    "    \"\"\"Encoder q(u|y)\"\"\"\n",
    "\n",
    "    def __init__(self, output_shape, input_shape):\n",
    "        super().__init__()\n",
    "        nc_in = input_shape[0]\n",
    "        nc_out = 2 * output_shape[0]\n",
    "\n",
    "        self.core_nn = nn.Sequential(\n",
    "            DenselyEncoder(\n",
    "                in_channels=nc_in,\n",
    "                out_channels=nc_out,\n",
    "                growth_rate=64,\n",
    "                steps=3,\n",
    "                scale_factor=1,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        mu, logvar = self.core_nn(input).chunk(2, 1)\n",
    "        return mu, F.hardtanh(logvar, min_val=-7, max_val=7.0)\n",
    "\n",
    "\n",
    "class p_y(nn.Module):\n",
    "    \"\"\"Dencoder p(y|u)\"\"\"\n",
    "\n",
    "    def __init__(self, output_shape, input_shape):\n",
    "        super().__init__()\n",
    "        nc_in = input_shape[0]\n",
    "        nc_out = n_embenddings(output_shape[0])\n",
    "\n",
    "        self.core_nn = nn.Sequential(\n",
    "            DenselyDecoder(\n",
    "                in_channels=nc_in,\n",
    "                out_channels=nc_out,\n",
    "                growth_rate=128,\n",
    "                steps=4,\n",
    "                scale_factor=1,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        logits = self.core_nn(input)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class q_z(nn.Module):\n",
    "    \"\"\"Encoder q(z|x)\"\"\"\n",
    "\n",
    "    def __init__(self, output_shape, input_shape):\n",
    "        super().__init__()\n",
    "        nc_in = input_shape[0]\n",
    "        nc_out = 2 * output_shape[0]\n",
    "\n",
    "        self.core_nn = nn.Sequential(\n",
    "            DenselyEncoder(\n",
    "                in_channels=nc_in,\n",
    "                out_channels=nc_out,\n",
    "                growth_rate=16,\n",
    "                steps=4,\n",
    "                scale_factor=2,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        mu, logvar = self.core_nn(input).chunk(2, 1)\n",
    "        return mu, F.hardtanh(logvar, min_val=-7, max_val=7.0)\n",
    "\n",
    "\n",
    "class DenselyDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        growth_rate=16,\n",
    "        steps=3,\n",
    "        scale_factor=2,\n",
    "        drop_prob=0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # upsample block\n",
    "        net = []\n",
    "        for i in range(scale_factor):\n",
    "            net.append(\n",
    "                DenseNetLayer(in_channels, growth_rate, steps, drop_prob=drop_prob)\n",
    "            )\n",
    "            in_channels = in_channels + growth_rate * steps\n",
    "            net.append(Upsample(in_channels, in_channels // 2, drop_prob=drop_prob))\n",
    "            in_channels = in_channels // 2\n",
    "            growth_rate = growth_rate // 2\n",
    "\n",
    "        # output block\n",
    "        net.append(\n",
    "            Conv2d(\n",
    "                in_channels, out_channels, kernel_size=3, stride=1, padding=1, act=None\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.core_nn = nn.Sequential(*net)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.core_nn(x)\n",
    "\n",
    "\n",
    "class p_z(nn.Module):\n",
    "    \"\"\"Encoder p(z| y, u)\"\"\"\n",
    "\n",
    "    def __init__(self, output_shape, input_shape):\n",
    "        super().__init__()\n",
    "        nc_y_in, nc_u_in = input_shape[0][0], input_shape[1][0]\n",
    "        nc_out = 2 * output_shape[0]\n",
    "\n",
    "        self.y_nn = nn.Sequential(\n",
    "            DenselyEncoder(\n",
    "                in_channels=nc_y_in,\n",
    "                out_channels=nc_out // 2,\n",
    "                growth_rate=32,\n",
    "                steps=5,\n",
    "                scale_factor=1,\n",
    "            ),\n",
    "            nn.ELU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.u_nn = nn.Sequential(\n",
    "            DenselyNetwork(\n",
    "                in_channels=nc_u_in,\n",
    "                out_channels=nc_out // 2,\n",
    "                growth_rate=64,\n",
    "                steps=3,\n",
    "                blocks=3,\n",
    "                act=True,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.core_nn = nn.Sequential(\n",
    "            DenselyNetwork(\n",
    "                in_channels=nc_out,\n",
    "                out_channels=nc_out,\n",
    "                growth_rate=64,\n",
    "                steps=3,\n",
    "                blocks=3,\n",
    "                act=None,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        y, u = input[0], input[1]\n",
    "\n",
    "        y_out = self.y_nn(y)\n",
    "        u_out = self.u_nn(u)\n",
    "\n",
    "        joint = torch.cat((y_out, u_out), 1)\n",
    "\n",
    "        mu, logvar = self.core_nn(joint).chunk(2, 1)\n",
    "        return mu, F.hardtanh(logvar, min_val=-7, max_val=7.0)\n",
    "\n",
    "\n",
    "class p_x(nn.Module):\n",
    "    \"\"\"p(x| y, z)\"\"\"\n",
    "\n",
    "    def __init__(self, output_shape, input_shape):\n",
    "        super().__init__()\n",
    "        nc_y_in, nc_z_in = input_shape[0][0], input_shape[1][0]\n",
    "        nc_out = n_embenddings(output_shape[0])\n",
    "\n",
    "        self.z_nn = nn.Sequential(\n",
    "            DenselyDecoder(\n",
    "                in_channels=nc_z_in,\n",
    "                out_channels=nc_out,\n",
    "                growth_rate=64,\n",
    "                steps=8,\n",
    "                scale_factor=2,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.core_nn = nn.Sequential(\n",
    "            DenselyNetwork(\n",
    "                in_channels=nc_out + 3,\n",
    "                out_channels=nc_out,\n",
    "                growth_rate=64,\n",
    "                steps=5,\n",
    "                blocks=3,\n",
    "                act=None,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        y, z = input[0], input[1]\n",
    "\n",
    "        y_out = F.interpolate(y, size=[256, 256], align_corners=False, mode=\"bilinear\")\n",
    "        z_out = self.z_nn(z)\n",
    "\n",
    "        joint = torch.cat((y_out, z_out), 1)\n",
    "        logits = self.core_nn(joint)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "\n",
    "class LowerBoundedExponentialLR(_LRScheduler):\n",
    "    def __init__(self, optimizer, gamma, lower_bound, last_epoch=-1):\n",
    "        self.gamma = gamma\n",
    "        self.lower_bound = lower_bound\n",
    "        super(LowerBoundedExponentialLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def _get_lr(self, base_lr):\n",
    "        lr = base_lr * self.gamma**self.last_epoch\n",
    "        if lr < self.lower_bound:\n",
    "            lr = self.lower_bound\n",
    "        return lr\n",
    "\n",
    "    def get_lr(self):\n",
    "        return [self._get_lr(base_lr) for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspired by https://github.com/ioangatop/srVAE\n",
    "class StandardNormal:\n",
    "    def __init__(self, z_shape):\n",
    "        self.z_shape = z_shape\n",
    "\n",
    "    def sample(self, n_samples=1, **kwargs):\n",
    "        return torch.randn((n_samples, *self.z_shape))\n",
    "\n",
    "    def log_p(self, z, **kwargs):\n",
    "        return self.forward(z)\n",
    "\n",
    "    def forward(self, z, **kwargs):\n",
    "        \"\"\"Outputs the log p(z).\"\"\"\n",
    "        log_probs = z.pow(2) + math.log(math.pi * 2.0)\n",
    "        log_probs = -0.5 * log_probs.view(z.size(0), -1).sum(dim=1)\n",
    "        return log_probs\n",
    "\n",
    "    def __call__(self, z, **kwargs):\n",
    "        return self.forward(z, **kwargs)\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"StandardNormal\"\n",
    "\n",
    "\n",
    "class ELBOLoss(_Loss):\n",
    "    \"\"\"\n",
    "    Computes negative ELBO loss and diagnostics.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input, outputs, model):\n",
    "        elbo = (\n",
    "            model.module.calculate_elbo\n",
    "            if isinstance(model, nn.DataParallel)\n",
    "            else model.calculate_elbo\n",
    "        )\n",
    "        return elbo(input, outputs)\n",
    "\n",
    "\n",
    "class srVAE(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        x_shape,  # 3, 256, 256\n",
    "        y_shape=(3, 128, 128),\n",
    "        u_dim: tuple[int, int, int] = (16, 8, 8),\n",
    "        z_dim: tuple[int, int, int] = (16, 8, 8),\n",
    "        device: str | torch.device = \"cpu\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.x_shape = x_shape\n",
    "        self.y_shape = y_shape\n",
    "\n",
    "        self.u_shape = u_dim\n",
    "        self.z_shape = z_dim\n",
    "\n",
    "        # q(y|x): deterministic \"compressed\" transformation\n",
    "        self.compressed_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize((self.y_shape[1], self.y_shape[2])),\n",
    "                transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # p(u)\n",
    "        self.p_u = StandardNormal(self.u_shape)\n",
    "\n",
    "        # q(u | y)\n",
    "        self.q_u = q_u(self.u_shape, self.y_shape)\n",
    "\n",
    "        # p(z | y)\n",
    "        self.p_z = p_z(self.z_shape, (self.y_shape, self.u_shape))\n",
    "\n",
    "        # q(z | x)\n",
    "        self.q_z = q_z(self.z_shape, self.x_shape)\n",
    "\n",
    "        # p(y | u)\n",
    "        self.p_y = p_y(self.y_shape, self.u_shape)\n",
    "\n",
    "        # p(x | y, z)\n",
    "        self.p_x = p_x(self.x_shape, (self.y_shape, self.z_shape))\n",
    "\n",
    "        # likelihood distribution\n",
    "        self.recon_loss = partial(dmol_loss)\n",
    "        self.sample_distribution = partial(sample_from_dmol)\n",
    "\n",
    "    def compressed_transformation(self, input):\n",
    "        y = []\n",
    "        for x in input:\n",
    "            y.append(self.compressed_transform(x.cpu()))\n",
    "        return torch.stack(y).to(self.device)\n",
    "\n",
    "    def initialize(self, dataloader):\n",
    "        \"\"\"Data dependent init for weight normalization\n",
    "        (Automatically done during the first forward pass).\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            x, _ = next(iter(dataloader))\n",
    "            x = x.to(self.device)\n",
    "            output = self.forward(x)\n",
    "            self.calculate_elbo(x, output)\n",
    "        return\n",
    "\n",
    "    @staticmethod\n",
    "    def reparameterize(z_mean, z_log_var):\n",
    "        \"\"\"z ~ N(z| z_mu, z_logvar)\"\"\"\n",
    "        epsilon = torch.randn_like(z_mean)\n",
    "        return z_mean + torch.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, n_samples=20):\n",
    "        # u ~ p(u)\n",
    "        u = self.p_u.sample(self.u_shape, n_samples=n_samples, device=self.device).to(\n",
    "            self.device\n",
    "        )\n",
    "\n",
    "        # p(y|u)\n",
    "        y_logits = self.p_y(u)\n",
    "        y_hat = self.sample_distribution(y_logits, nc=self.y_shape[0])\n",
    "\n",
    "        # z ~ p(z|y, u)\n",
    "        z_p_mean, z_p_logvar = self.p_z((y_hat, u))\n",
    "        z_p = self.reparameterize(z_p_mean, z_p_logvar)\n",
    "\n",
    "        # x ~ p(x|y,z)\n",
    "        x_logits = self.p_x((y_hat, z_p))\n",
    "        x_hat = self.sample_distribution(x_logits, nc=self.x_shape[0])\n",
    "        return x_hat, y_hat\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def reconstruct(self, x, **kwargs):\n",
    "        outputs = self.forward(x)\n",
    "        y_hat = self.sample_distribution(outputs.get(\"y_logits\"), nc=self.y_shape[0])\n",
    "        x_hat = self.sample_distribution(outputs.get(\"x_logits\"), nc=self.x_shape[0])\n",
    "        return outputs.get(\"y\"), y_hat, x_hat\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def super_resolution(self, y):\n",
    "        # u ~ q(u| y)\n",
    "        u_q_mean, u_q_logvar = self.q_u(y)\n",
    "        u_q = self.reparameterize(u_q_mean, u_q_logvar)\n",
    "\n",
    "        # z ~ p(z|y)\n",
    "        z_p_mean, z_p_logvar = self.p_z((y, u_q))\n",
    "        z_p = self.reparameterize(z_p_mean, z_p_logvar)\n",
    "\n",
    "        # x ~ p(x|y,z)\n",
    "        x_logits = self.p_x((y, z_p))\n",
    "        x_hat = self.sample_distribution(x_logits)\n",
    "        return x_hat\n",
    "\n",
    "    def calculate_elbo(self, x, outputs, **kwargs):\n",
    "        # unpack variables\n",
    "        y, x_logits, y_logits = (\n",
    "            outputs.get(\"y\"),\n",
    "            outputs.get(\"x_logits\"),\n",
    "            outputs.get(\"y_logits\"),\n",
    "        )\n",
    "        u_q, u_q_mean, u_q_logvar = (\n",
    "            outputs.get(\"u_q\"),\n",
    "            outputs.get(\"u_q_mean\"),\n",
    "            outputs.get(\"u_q_logvar\"),\n",
    "        )\n",
    "        z_q, z_q_mean, z_q_logvar = (\n",
    "            outputs.get(\"z_q\"),\n",
    "            outputs.get(\"z_q_mean\"),\n",
    "            outputs.get(\"z_q_logvar\"),\n",
    "        )\n",
    "        z_p_mean, z_p_logvar = outputs.get(\"z_p_mean\"), outputs.get(\"z_p_logvar\")\n",
    "\n",
    "        # Reconstraction loss\n",
    "        RE_x = self.recon_loss(x, x_logits, nc=self.x_shape[0])\n",
    "        RE_y = self.recon_loss(y, y_logits, nc=self.y_shape[0])\n",
    "\n",
    "        # Regularization loss\n",
    "        log_p_u = self.p_u.log_p(u_q, dim=1)\n",
    "        log_q_u = log_normal_diag(u_q, u_q_mean, u_q_logvar)\n",
    "        KL_u = log_q_u - log_p_u\n",
    "\n",
    "        log_p_z = log_normal_diag(z_q, z_p_mean, z_p_logvar)\n",
    "        log_q_z = log_normal_diag(z_q, z_q_mean, z_q_logvar)\n",
    "        KL_z = log_q_z - log_p_z\n",
    "\n",
    "        # Total lower bound loss\n",
    "        nelbo = -(RE_x + RE_y - KL_u - KL_z).mean()\n",
    "\n",
    "        diagnostics = {\n",
    "            \"bpd\": (nelbo.item()) / (np.prod(x.shape[1:]) * np.log(2.0)),\n",
    "            \"nelbo\": nelbo.item(),\n",
    "            \"RE\": -(RE_x + RE_y).mean().item(),\n",
    "            \"RE_x\": -RE_x.mean().item(),\n",
    "            \"RE_y\": -RE_y.mean().item(),\n",
    "            \"KL\": (KL_z + KL_u).mean().item(),\n",
    "            \"KL_u\": KL_u.mean().item(),\n",
    "            \"KL_z\": KL_z.mean().item(),\n",
    "        }\n",
    "        return nelbo, diagnostics\n",
    "\n",
    "    def forward(self, x, y, **kwargs):\n",
    "        \"\"\"Forward pass through the inference and the generative model.\"\"\"\n",
    "        # y ~ f(x) (deterministc)\n",
    "        # y = self.compressed_transformation(x)\n",
    "\n",
    "        # u ~ q(u| y)\n",
    "        u_q_mean, u_q_logvar = self.q_u(y)\n",
    "        u_q = self.reparameterize(u_q_mean, u_q_logvar)\n",
    "\n",
    "        # z ~ q(z| x, y)\n",
    "        z_q_mean, z_q_logvar = self.q_z(x)\n",
    "        z_q = self.reparameterize(z_q_mean, z_q_logvar)\n",
    "\n",
    "        # x ~ p(x| y, z)\n",
    "        x_logits = self.p_x((y, z_q))\n",
    "\n",
    "        # y ~ p(y| u)\n",
    "        y_logits = self.p_y(u_q)\n",
    "\n",
    "        # z ~ p(z| x)\n",
    "        z_p_mean, z_p_logvar = self.p_z((y, u_q))\n",
    "\n",
    "        return {\n",
    "            \"u_q_mean\": u_q_mean,\n",
    "            \"u_q_logvar\": u_q_logvar,\n",
    "            \"u_q\": u_q,\n",
    "            \"z_q_mean\": z_q_mean,\n",
    "            \"z_q_logvar\": z_q_logvar,\n",
    "            \"z_q\": z_q,\n",
    "            \"z_p_mean\": z_p_mean,\n",
    "            \"z_p_logvar\": z_p_logvar,\n",
    "            \"y\": y,\n",
    "            \"y_logits\": y_logits,\n",
    "            \"x_logits\": x_logits,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = create_train_test_split(\n",
    "    str(SITES_DIR) + \"\\\\\", seed=42, sites={\"K34-AMAZ\"}\n",
    ")\n",
    "train_loader = DataLoader(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(969, 416)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mitch\\Files\\GitHub\\stat3007-project\\myenv\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "model = srVAE((3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = ELBOLoss()\n",
    "optimizer = torch.optim.Adamax(\n",
    "    model.parameters(), lr=2e-3, betas=(0.9, 0.999), eps=1e-7\n",
    ")\n",
    "scheduler = LowerBoundedExponentialLR(optimizer, gamma=0.999999, lower_bound=0.0001)\n",
    "\n",
    "\n",
    "def train(model, train_loader):\n",
    "    model.train()\n",
    "\n",
    "    acc_losses = {}\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        x = x.to(\"cpu\")\n",
    "        x = x[:, :3, :, :]\n",
    "        y = y[:, :3, :, :]\n",
    "        output = model(y, x)\n",
    "        loss, diagnostics = criterion(x, output, model)\n",
    "        # back-prop\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        # # gather statistics\n",
    "        # acc_losses = Counter(acc_losses) + Counter(diagnostics)\n",
    "        # log_interval(i + 1, len(train_loader), acc_losses)\n",
    "    avg_losses = {k: acc_losses[k] / len(train_loader) for k in acc_losses}\n",
    "    return avg_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mitch\\AppData\\Local\\Temp\\ipykernel_4352\\4233591179.py:70: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ..\\aten\\src\\ATen\\native\\ReduceOps.cpp:1760.)\n",
      "  m_init, v_init = torch.mean(t, 0), torch.var(t, 0)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (256) must match the size of tensor b (128) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     train_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[86], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader)\u001b[0m\n\u001b[0;32m     17\u001b[0m y \u001b[38;5;241m=\u001b[39m y[:, :\u001b[38;5;241m3\u001b[39m, :, :]\n\u001b[0;32m     18\u001b[0m output \u001b[38;5;241m=\u001b[39m model(y, x)\n\u001b[1;32m---> 19\u001b[0m loss, diagnostics \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# back-prop\u001b[39;00m\n\u001b[0;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward(retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\mitch\\Files\\GitHub\\stat3007-project\\myenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mitch\\Files\\GitHub\\stat3007-project\\myenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[82], line 39\u001b[0m, in \u001b[0;36mELBOLoss.forward\u001b[1;34m(self, input, outputs, model)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, outputs, model):\n\u001b[0;32m     34\u001b[0m     elbo \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     35\u001b[0m         model\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39mcalculate_elbo\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, nn\u001b[38;5;241m.\u001b[39mDataParallel)\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m model\u001b[38;5;241m.\u001b[39mcalculate_elbo\n\u001b[0;32m     38\u001b[0m     )\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43melbo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[82], line 175\u001b[0m, in \u001b[0;36msrVAE.calculate_elbo\u001b[1;34m(self, x, outputs, **kwargs)\u001b[0m\n\u001b[0;32m    172\u001b[0m z_p_mean, z_p_logvar \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz_p_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m), outputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz_p_logvar\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# Reconstraction loss\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m RE_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecon_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m RE_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecon_loss(y, y_logits, nc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_shape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# Regularization loss\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[27], line 67\u001b[0m, in \u001b[0;36mdmol_loss\u001b[1;34m(x, output, nc, nmix, nbits)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# channel-wise conditional modelling sub-pixels\u001b[39;00m\n\u001b[0;32m     66\u001b[0m mean0 \u001b[38;5;241m=\u001b[39m means[:, :, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 67\u001b[0m mean1 \u001b[38;5;241m=\u001b[39m means[:, :, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[43mcoeffs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     68\u001b[0m mean2 \u001b[38;5;241m=\u001b[39m means[:, :, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m coeffs[:, :, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m x[:, :, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m coeffs[:, :, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m*\u001b[39m x[:, :, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     69\u001b[0m means \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([mean0, mean1, mean2], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (256) must match the size of tensor b (128) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 2):\n",
    "    train_losses = train(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_losses\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_losses' is not defined"
     ]
    }
   ],
   "source": [
    "train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "getafix_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
