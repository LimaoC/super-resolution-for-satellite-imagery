# -*- coding: utf-8 -*-
"""prototype-srgan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jXYYlFZtMgrD2BTZ6uQi5Id33Ke07CTu
"""


import time
import pathlib

import torch
import super_resolution.src.srgan as model
from torch import nn
from torch import optim
from torch.cuda import amp
from torch.backends import cudnn
from torch.utils.data import DataLoader


from super_resolution.src.sen2venus_dataset import create_train_test_split

DATA_DIR = pathlib.Path("/data/s4702696/share/data")
SITES_DIR = DATA_DIR

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# torch.backends.cudnn.benchmark=False

train_data, test_data = create_train_test_split(
    str(SITES_DIR) + "/", seed=42, sites={"K34-AMAZ"}, device="cpu"
)
train_loader = DataLoader(train_data, batch_size=2, pin_memory=True)


def train(g_model,
          d_model,
          train_loader: DataLoader,
          pixel_criterion: nn.L1Loss,
          # content_criterion: model.ContentLoss,
          adversarial_criterion: nn.BCEWithLogitsLoss,
          generator_optimizer: optim.Adam,
          discriminator_optimizer: optim.Adam,
          epoch: int,
          scaler: amp.GradScaler,
          # writer: SummaryWriter,
          device: torch.device,
          config):
  g_model.train()
  d_model.train()

  # using vgg
  batch_size = train_loader.batch_size
  real_label = torch.full([batch_size, 1], 1.0, dtype=torch.float, device=device)
  fake_label = torch.full([batch_size, 1], 0.0, dtype=torch.float, device=device)

  # Loss component weights
  pixel_weight = torch.Tensor([1]).to(device)
  adversarial_weight = torch.Tensor([0.001]).to(device)

  for (low_res, high_res) in train_loader:
    # print(i)
    low_res = low_res[:, :3, :, :]
    high_res = high_res[:, :3, :, :]
    low_res = low_res.to(device)
    high_res = high_res.to(device)

    # # image data augmentation
    # gt, lr = random_crop_torch(gt,
    #                             lr,
    #                             config["TRAIN"]["DATASET"]["GT_IMAGE_SIZE"],
    #                             config["SCALE"])
    # gt, lr = random_rotate_torch(gt, lr, config["SCALE"], [0, 90, 180, 270])
    # gt, lr = random_vertically_flip_torch(gt, lr)
    # gt, lr = random_horizontally_flip_torch(gt, lr)

    # Generator training
    ######################
    for d_parameters in d_model.parameters():
      d_parameters.requires_grad = False
      d_model.zero_grad(set_to_none=True)

    # Initialize the generator model gradient
    g_model.zero_grad(set_to_none=True)

    # Calculate the perceptual loss of the generator, mainly including pixel loss,
    # feature loss and confrontation loss
    with amp.autocast():
        super_res = g_model(low_res)
        pixel_loss = pixel_criterion(super_res, high_res)
        # feature_loss = content_criterion(sr, gt)
        adversarial_loss = adversarial_criterion(d_model(super_res), real_label)
        pixel_loss = torch.sum(torch.mul(pixel_weight, pixel_loss))
        # feature_loss = torch.sum(torch.mul(feature_weight, feature_loss))
        adversarial_loss = torch.sum(torch.mul(adversarial_weight, adversarial_loss))
        # Compute generator total loss
        generator_loss = pixel_loss + adversarial_loss # + feature_loss

    # Backpropagation generator loss on generated samples
    scaler.scale(generator_loss).backward()

    # update generator model weights
    scaler.step(generator_optimizer)
    scaler.update()
    #########################################

    # Discriminator training
    ##########################
    for d_parameters in d_model.parameters():
      d_parameters.requires_grad = True

    # Initialize the discriminator model gradient
    d_model.zero_grad(set_to_none=True)

    # Calculate the classification score of the discriminator model on real samples
    with amp.autocast():
      high_res_output = d_model(high_res)
      discriminator_loss_high_res = adversarial_criterion(high_res_output, real_label)

    # backpropagate discriminator's loss on real samples
    scaler.scale(discriminator_loss_high_res).backward()

    # Calculate the classification score of the generated samples by the discriminator model
    with amp.autocast():
        super_res_output = d_model(super_res.detach().clone())
        discriminator_loss_super_res = adversarial_criterion(super_res_output, fake_label)
    # backpropagate discriminator loss on generated samples
    scaler.scale(discriminator_loss_super_res).backward()

    # Compute the discriminator total loss value
    d_loss = discriminator_loss_high_res + discriminator_loss_super_res
    # Update discriminator model weights
    scaler.step(d_optimizer)
    scaler.update()
    # ###############################

    # print(f"generator loss: {generator_loss}"
    #       f" | real discrim loss {discriminator_loss_high_res}"
    #       f" | fake discrim loss {discriminator_loss_super_res}")

cudnn.benchmark = True

g_model = model.SRResNet(in_channels=3,
            out_channels=3,
            channels=64,
            num_rcb=16,
            upscale=2,)
d_model = model.DiscriminatorForVGG(in_channels=3, out_channels=1, channels=64)

pixel_criterion = nn.MSELoss()
adversarial_criterion = nn.BCEWithLogitsLoss()

g_optimizer = optim.Adam(g_model.parameters(),
                         lr = 0.0001,
                         betas=(0.9, 0.999),
                         eps=0.0001,
                         weight_decay=0)
d_optimizer = optim.Adam(d_model.parameters(),
                         lr = 0.0001,
                         betas=(0.9, 0.999),
                         eps=0.0001,
                         weight_decay=0)
g_model = nn.DataParallel(g_model)
d_model = nn.DataParallel(d_model)

g_model = g_model.to(device)
d_model = d_model.to(device)


for epoch in range(2):
  start = time.time()
  train(g_model,
        d_model,
        train_loader,
        pixel_criterion,
        # content_criterion,
        adversarial_criterion,
        g_optimizer,
        d_optimizer,
        epoch,
        amp.GradScaler(),
        # writer,
        device,
        {})
  end = time.time()
  print(f"Time taken for epoch {epoch}: {end - start}")
